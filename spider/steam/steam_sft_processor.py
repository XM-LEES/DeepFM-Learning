import pandas as pd
import json
import ast
import os

# ==========================================
# 1. å®Œæ•´çš„ Steam Tag æ˜ å°„å­—å…¸ (ç›´æ¥ç¡¬ç¼–ç åœ¨è¿™é‡Œ)
# ==========================================
# è¿™æ˜¯åŸºäº Steam æ•°æ®åº“æ•´ç†çš„é«˜é¢‘æ ‡ç­¾ï¼Œæ¶µç›–äº†ç»å¤§å¤šæ•°çƒ­é—¨ Tag
STEAM_TAG_MAP = {
    # --- æ ¸å¿ƒåˆ†ç±» ---
    19: "åŠ¨ä½œ", 122: "RPG", 599: "ç­–ç•¥", 21: "å†’é™©", 
    1662: "æ¨¡æ‹Ÿ", 597: "ä¼‘é—²", 701: "ä½“è‚²", 699: "ç«é€Ÿ", 492: "ç‹¬ç«‹",
    
    # --- ç©æ³•æœºåˆ¶ ---
    1774: "å°„å‡»", 1663: "ç±»Rogue", 1695: "å¼€æ”¾ä¸–ç•Œ", 1664: "è§£è°œ", 
    1742: "è§†è§‰å°è¯´", 1669: "å¤§é€ƒæ€", 1625: "å¹³å°è·³è·ƒ", 1734: "å¡ç‰Œæ„å»º", 
    1743: "æ ¼æ–—", 1756: "å¡”é˜²", 1708: "æˆ˜æœ¯", 3859: "å¤šäºº", 4182: "å•äºº",
    
    # --- é¢˜æ/é£æ ¼ ---
    3942: "ç§‘å¹»", 1684: "å¥‡å¹»", 1667: "ææ€–", 4172: "ä¸­ä¸–çºª", 
    1755: "èµ›åšæœ‹å…‹", 3839: "åæœ«æ—¥", 1036: "åŠ¨æ¼«", 4085: "åƒç´ é£",
    4175: "å‰§æƒ…ä¸°å¯Œ", 4667: "æŠ¢å…ˆä½“éªŒ", 4345: "è¡€è…¥", 4637: "ç±»é­‚", 
    1685: "æ²™ç›’", 1687: "æ½œè¡Œ", 1697: "ç æ€", 1716: "èŠ‚å¥", 
    113: "å…è´¹å¼€ç©", 3878: "ç«æŠ€"
}

def get_tag_names(tag_id_list):
    """
    è¾“å…¥: [19, 1774, 99999]
    è¾“å‡º: "åŠ¨ä½œ, å°„å‡»" (è¿‡æ»¤æ‰ä¸è®¤è¯†çš„ ID)
    """
    if not isinstance(tag_id_list, list):
        return ""
    
    names = []
    for tid in tag_id_list:
        if tid in STEAM_TAG_MAP:
            names.append(STEAM_TAG_MAP[tid])
    
    return ", ".join(names)

def generate_sft_dataset():
    input_file = "../../data/steam/steam_raw_data.csv"
    output_file = "../../data/steam/steam_sft_train.json"

    print(f"âš™ï¸ [SFT] å¼€å§‹å¤„ç†æ•°æ®ï¼Œè¯»å–: {input_file} ...")
    
    if not os.path.exists(input_file):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ° {input_file}ï¼Œè¯·å…ˆè¿è¡Œ Step 1 Plus çˆ¬è™«ï¼")
        return

    df = pd.read_csv(input_file)
    sft_data = []
    
    # éå†æ¯ä¸€è¡Œæ•°æ®
    for index, row in df.iterrows():
        try:
            # 1. è§£æåŸºç¡€ä¿¡æ¯
            title = row['title']
            
            # 2. è§£æ Tags (CSVè¯»å–åæ˜¯å­—ç¬¦ä¸²ï¼Œéœ€è¦è½¬å›åˆ—è¡¨)
            # å…¼å®¹å¤„ç†ï¼šæœ‰äº›å¯èƒ½æ˜¯ float('nan')
            tags_raw = row['tags_raw']
            if pd.isna(tags_raw):
                tags_list = []
            elif isinstance(tags_raw, str):
                tags_list = json.loads(tags_raw) # æˆ–è€… ast.literal_eval(tags_raw)
            else:
                tags_list = tags_raw
            
            # === ğŸŸ¢ æ ¸å¿ƒï¼šè°ƒç”¨æ˜ å°„å­—å…¸è½¬ä¸­æ–‡ ===
            tag_str_cn = get_tag_names(tags_list)
            if not tag_str_cn: 
                tag_str_cn = "æœªçŸ¥ç±»å‹"

            # 3. è§£æè¯„è®º (Reviews)
            # æˆ‘ä»¬çš„çˆ¬è™«å­˜çš„æ˜¯ JSON å­—ç¬¦ä¸² '["è¯„è®º1", "è¯„è®º2"]'
            reviews_raw = row['user_reviews']
            if pd.isna(reviews_raw):
                continue
                
            if isinstance(reviews_raw, str):
                reviews_list = json.loads(reviews_raw)
            else:
                reviews_list = reviews_raw

            if not reviews_list:
                continue

            # 4. æ„é€  SFT æ•°æ®å¯¹ (ä¸€å¯¹å¤š)
            # ä¸€ä¸ªæ¸¸æˆæœ‰å¤šæ¡è¯„è®ºï¼Œå¯ä»¥ç”Ÿæˆå¤šæ¡è®­ç»ƒæ•°æ®ï¼Œæå¤§æ‰©å……æ•°æ®é›†ï¼
            for review_content in reviews_list:
                # ç¨å¾®æ¸…æ´—ä¸€ä¸‹è¯„è®ºï¼Œå»æ‰æ¢è¡Œç¬¦
                clean_review = review_content.replace('\n', ' ').strip()
                
                # åªæœ‰å½“è¯„è®ºé•¿åº¦é€‚ä¸­æ—¶æ‰è¦ (å¤ªçŸ­æ²¡ä¿¡æ¯é‡ï¼Œå¤ªé•¿å®¹æ˜“è¶… token)
                if 5 < len(clean_review) < 500:
                    sample = {
                        "instruction": f"è¯·ä»¥èµ„æ·±ç©å®¶çš„èº«ä»½ï¼Œç‚¹è¯„ä¸€ä¸‹ã€Š{title}ã€‹è¿™æ¬¾æ¸¸æˆã€‚",
                        "input": f"æ¸¸æˆç±»å‹æ ‡ç­¾ï¼š{tag_str_cn}",
                        "output": clean_review
                    }
                    sft_data.append(sample)

        except Exception as e:
            # æ‰“å°é”™è¯¯ä½†ä¸ä¸­æ–­ï¼Œæ–¹ä¾¿è°ƒè¯•
            print(f"âš ï¸ è·³è¿‡ç¬¬ {index} è¡Œ: {e}")
            continue

    # ä¿å­˜ä¸º JSON (LLaMA-Factory æ ‡å‡†æ ¼å¼)
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(sft_data, f, ensure_ascii=False, indent=2)

    print(f"\nâœ… SFT æ•°æ®é›†æ„å»ºå®Œæˆï¼")
    print(f"   ğŸ“Š åŸå§‹æ¸¸æˆæ•°: {len(df)}")
    print(f"   ğŸš€ ç”Ÿæˆå¾®è°ƒæ ·æœ¬æ•°: {len(sft_data)} (ä¸€ä¸ªæ¸¸æˆå¯¹åº”å¤šæ¡è¯„è®º)")
    print(f"   ğŸ’¾ å·²ä¿å­˜è‡³: {output_file}")
    
    # æ‰“å°ä¸€æ¡é¢„è§ˆçœ‹çœ‹æ•ˆæœ
    if sft_data:
        print("\nğŸ” æ•°æ®æ ·æœ¬é¢„è§ˆ:")
        print(json.dumps(sft_data[0], ensure_ascii=False, indent=2))

if __name__ == "__main__":
    generate_sft_dataset()