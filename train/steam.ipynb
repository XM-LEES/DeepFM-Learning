{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12086bde-d748-4e5f-9fdf-3ebb9832a32c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T13:52:22.776211Z",
     "iopub.status.busy": "2025-12-15T13:52:22.776092Z",
     "iopub.status.idle": "2025-12-15T13:52:26.841981Z",
     "shell.execute_reply": "2025-12-15T13:52:26.841331Z",
     "shell.execute_reply.started": "2025-12-15T13:52:22.776197Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.cloud.aliyuncs.com/pypi/simple\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/site-packages (2.9.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/site-packages (2.3.5)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/site-packages (1.7.2)\n",
      "Requirement already satisfied: deepctr-torch in /usr/local/lib/python3.11/site-packages (0.2.9)\n",
      "Requirement already satisfied: flask in /usr/local/lib/python3.11/site-packages (3.1.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/site-packages (2.32.5)\n",
      "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/site-packages (7.5.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.11/site-packages (from torch) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.11/site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.11/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.11/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.11/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.11/site-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.11/site-packages (from torch) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.11/site-packages (from torch) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.11/site-packages (from torch) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.11/site-packages (from torch) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.11/site-packages (from torch) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.11/site-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.11/site-packages (from torch) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.11/site-packages (from torch) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.11/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.11/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.11/site-packages (from torch) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.1 in /usr/local/lib/python3.11/site-packages (from torch) (3.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/site-packages (from pandas) (2025.3)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.11/site-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/site-packages (from deepctr-torch) (4.67.1)\n",
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/site-packages (from deepctr-torch) (2.20.0)\n",
      "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/site-packages (from flask) (1.9.0)\n",
      "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/site-packages (from flask) (8.2.1)\n",
      "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/site-packages (from flask) (2.2.0)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/site-packages (from flask) (3.0.3)\n",
      "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.11/site-packages (from flask) (3.1.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests) (2.6.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests) (2025.11.12)\n",
      "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/site-packages (from pyngrok) (6.0.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/site-packages (from tensorflow->deepctr-torch) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/site-packages (from tensorflow->deepctr-torch) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/site-packages (from tensorflow->deepctr-torch) (25.9.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/site-packages (from tensorflow->deepctr-torch) (0.7.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in /usr/local/lib/python3.11/site-packages (from tensorflow->deepctr-torch) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/site-packages (from tensorflow->deepctr-torch) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in /usr/local/lib/python3.11/site-packages (from tensorflow->deepctr-torch) (3.4.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/site-packages (from tensorflow->deepctr-torch) (25.0)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in /usr/local/lib/python3.11/site-packages (from tensorflow->deepctr-torch) (6.33.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/site-packages (from tensorflow->deepctr-torch) (65.5.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/site-packages (from tensorflow->deepctr-torch) (3.2.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/site-packages (from tensorflow->deepctr-torch) (2.0.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/site-packages (from tensorflow->deepctr-torch) (1.76.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in /usr/local/lib/python3.11/site-packages (from tensorflow->deepctr-torch) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in /usr/local/lib/python3.11/site-packages (from tensorflow->deepctr-torch) (3.12.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/site-packages (from tensorflow->deepctr-torch) (3.15.1)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.11/site-packages (from tensorflow->deepctr-torch) (0.5.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow->deepctr-torch) (0.45.1)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.11/site-packages (from keras>=3.10.0->tensorflow->deepctr-torch) (14.2.0)\n",
      "Requirement already satisfied: namex in /usr/local/lib/python3.11/site-packages (from keras>=3.10.0->tensorflow->deepctr-torch) (0.1.0)\n",
      "Requirement already satisfied: optree in /usr/local/lib/python3.11/site-packages (from keras>=3.10.0->tensorflow->deepctr-torch) (0.18.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/site-packages (from tensorboard~=2.20.0->tensorflow->deepctr-torch) (3.10)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.11/site-packages (from tensorboard~=2.20.0->tensorflow->deepctr-torch) (12.0.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/site-packages (from tensorboard~=2.20.0->tensorflow->deepctr-torch) (0.7.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/site-packages (from rich->keras>=3.10.0->tensorflow->deepctr-torch) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/site-packages (from rich->keras>=3.10.0->tensorflow->deepctr-torch) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow->deepctr-torch) (0.1.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# ğŸ® å®‰è£…æ‰€éœ€ä¾èµ–\n",
    "!pip install torch deepctr-torch pandas numpy scikit-learn flask requests pyngrok matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8298d8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import torch\n",
    "import random\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from deepctr_torch.inputs import SparseFeat, DenseFeat, VarLenSparseFeat\n",
    "from deepctr_torch.models import DeepFM\n",
    "\n",
    "# ==========================================\n",
    "# âš™ï¸ å…¨å±€é…ç½®ä¸­å¿ƒ (Global Config)\n",
    "# ==========================================\n",
    "class SteamConfig:\n",
    "    # 1. æ•°æ®è·¯å¾„\n",
    "    CSV_PATH = '../data/steam/deepfm_train_100k.csv' # ä½ çš„è®­ç»ƒæ–‡ä»¶è·¯å¾„\n",
    "    MODEL_PATH = 'deepfm_steam_weights.pth'          # æ¨¡å‹ä¿å­˜è·¯å¾„\n",
    "    \n",
    "    # 2. ç‰¹å¾å‚æ•°\n",
    "    MAX_TAG_LEN = 5          # æ¯ä¸ªæ¸¸æˆæœ€å¤šå–å¤šå°‘ä¸ª Tag\n",
    "    EMBEDDING_DIM = 64       # è¯å‘é‡ç»´åº¦ (å»ºè®® 32 æˆ– 64)\n",
    "    \n",
    "    # 3. ç½‘ç»œç»“æ„\n",
    "    # å»ºè®®ä¸è¦å¤ªå¤§ï¼Œæ¨è (256, 128) æˆ– (128, 128)\n",
    "    DNN_HIDDEN_UNITS = (128, 64) \n",
    "    DNN_DROPOUT = 0.5\n",
    "    \n",
    "    # 4. è®­ç»ƒå‚æ•°\n",
    "    BATCH_SIZE = 1024\n",
    "    EPOCHS = 20              # 20è½®ä¸€èˆ¬å°±å¤Ÿäº†\n",
    "    DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    SEED = 2024\n",
    "\n",
    "# å®ä¾‹åŒ–é…ç½®\n",
    "cfg = SteamConfig()\n",
    "print(f\"ğŸ”¥ å½“å‰é…ç½® -> è®¾å¤‡: {cfg.DEVICE} | ç½‘ç»œç»“æ„: {cfg.DNN_HIDDEN_UNITS}\")\n",
    "\n",
    "# --- å›ºå®šéšæœºç§å­ (ä¿è¯ç»“æœå¯å¤ç°) ---\n",
    "def seed_everything(seed=2024):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_everything(cfg.SEED)\n",
    "\n",
    "# --- åºåˆ—è¡¥é½å‡½æ•° ---\n",
    "def pad_sequences(sequences, maxlen, value=0):\n",
    "    \"\"\"æŠŠå˜é•¿çš„ Tag åˆ—è¡¨è¡¥é½ä¸ºå®šé•¿\"\"\"\n",
    "    result = np.full((len(sequences), maxlen), value, dtype=np.int32)\n",
    "    for i, seq in enumerate(sequences):\n",
    "        if len(seq) > 0:\n",
    "            trunc = seq[:maxlen]\n",
    "            result[i, :len(trunc)] = trunc\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198453dc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Steam æ•°æ®åŠ è½½ä¸é¢„å¤„ç†\n",
    "\n",
    "æ ¹æ® Config è‡ªåŠ¨è°ƒæ•´è¯è¡¨å¤§å°å’Œç‰¹å¾ç»´åº¦ã€‚\n",
    "\n",
    "æ ¸å¿ƒé€»è¾‘ï¼š\n",
    "\n",
    "1. å¤„ç† tags_list: å®ƒæ˜¯å­—ç¬¦ä¸²æ ¼å¼çš„åˆ—è¡¨ \"[1663, 1774]\"ï¼Œéœ€è¦è¿˜åŸå¹¶è¡¥é½é•¿åº¦ã€‚\n",
    "\n",
    "2. å¤„ç† price: å½’ä¸€åŒ–ã€‚\n",
    "\n",
    "3. å¤„ç† item_id: å»ºç«‹ç´¢å¼•æ˜ å°„ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1545474",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2025-12-15T13:52:26.842887Z",
     "iopub.status.busy": "2025-12-15T13:52:26.842697Z",
     "iopub.status.idle": "2025-12-15T13:52:30.648526Z",
     "shell.execute_reply": "2025-12-15T13:52:30.647839Z",
     "shell.execute_reply.started": "2025-12-15T13:52:26.842871Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-15 21:52:28.847640: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-15 21:52:28.896481: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-12-15 21:52:30.200857: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "def load_steam_data(csv_path, config):\n",
    "    print(f\"ğŸ“‚ æ­£åœ¨åŠ è½½æ•°æ®: {csv_path} ...\")\n",
    "    # 1. è¯»å– CSV\n",
    "    data = pd.read_csv(csv_path)\n",
    "    \n",
    "    # 2. å¤„ç† Tag åˆ—è¡¨å­—ç¬¦ä¸² \"[1, 2]\" -> [1, 2]\n",
    "    # ä½ çš„æ•°æ®é‡Œ tags_list æ˜¯å­—ç¬¦ä¸²ï¼Œå¿…é¡»è½¬æ¢\n",
    "    data['tags_list'] = data['tags_list'].apply(lambda x: ast.literal_eval(x))\n",
    "    \n",
    "    # --- Tag ç¼–ç  ---\n",
    "    all_tags = [tag for sublist in data['tags_list'] for tag in sublist]\n",
    "    # è·å–æœ€å¤§ Tag ID (å‡è®¾ Tag ID æ˜¯æ•°å­—ä¸”ä»1å¼€å§‹ï¼Œå¦‚æœä¸æ˜¯è¿ç»­çš„ï¼Œå»ºè®®ç”¨ LabelEncoder)\n",
    "    # è¿™é‡Œä¸ºäº†ä¿é™©ï¼Œæˆ‘ä»¬ç”¨ LabelEncoder é‡æ–°ç¼–ä¸€éï¼Œä¿è¯ ID è¿ç»­\n",
    "    tag_lbe = LabelEncoder()\n",
    "    tag_lbe.fit(all_tags)\n",
    "    max_tag_id = len(tag_lbe.classes_) + 1\n",
    "    \n",
    "    # å°†åŸå§‹ Tag æ˜ å°„ä¸º 1~N çš„ç´¢å¼• (0ç•™ç»™Padding)\n",
    "    data['tags_list'] = data['tags_list'].apply(\n",
    "        lambda x: [i + 1 for i in tag_lbe.transform(x)] if len(x) > 0 else []\n",
    "    )\n",
    "    \n",
    "    # --- ItemID ç¼–ç  ---\n",
    "    item_lbe = LabelEncoder()\n",
    "    data['item_id_idx'] = item_lbe.fit_transform(data['item_id'])\n",
    "    max_item_id = data['item_id_idx'].max() + 1\n",
    "    \n",
    "    # --- Price å½’ä¸€åŒ– ---\n",
    "    mms = MinMaxScaler(feature_range=(0, 1))\n",
    "    data['price_norm'] = mms.fit_transform(data[['price']])\n",
    "    \n",
    "    # 3. åºåˆ—è¡¥é½\n",
    "    tags_padded = pad_sequences(list(data['tags_list']), maxlen=config.MAX_TAG_LEN, value=0)\n",
    "    \n",
    "    # 4. å®šä¹‰ç‰¹å¾åˆ— (Feature Columns)\n",
    "    fixlen_feature_columns = [\n",
    "        SparseFeat('item_id_idx', vocabulary_size=max_item_id, embedding_dim=config.EMBEDDING_DIM),\n",
    "        DenseFeat('price_norm', dimension=1)\n",
    "    ]\n",
    "    \n",
    "    varlen_feature_columns = [\n",
    "        VarLenSparseFeat(\n",
    "            SparseFeat('tags', vocabulary_size=max_tag_id, embedding_dim=config.EMBEDDING_DIM),\n",
    "            maxlen=config.MAX_TAG_LEN, combiner='mean', length_name=None\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    linear_feature_columns = fixlen_feature_columns + varlen_feature_columns\n",
    "    dnn_feature_columns = fixlen_feature_columns + varlen_feature_columns\n",
    "    \n",
    "    # 5. ç»„è£… Input\n",
    "    model_input = {\n",
    "        'item_id_idx': data['item_id_idx'].values,\n",
    "        'price_norm': data['price_norm'].values,\n",
    "        'tags': tags_padded\n",
    "    }\n",
    "    \n",
    "    target = data['label'].values\n",
    "    \n",
    "    # è¿”å›æ•°æ®å’Œä»æ•°æ®ä¸­ç»Ÿè®¡å‡ºçš„ç‰¹å¾å®šä¹‰\n",
    "    return model_input, linear_feature_columns, dnn_feature_columns, target, data\n",
    "\n",
    "# æµ‹è¯•ä¸€ä¸‹\n",
    "# input_dict, linear_cols, dnn_cols, target, df_raw = load_steam_data(cfg.CSV_PATH, cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ce3e68",
   "metadata": {},
   "source": [
    "## Steam æ¨¡å‹è®­ç»ƒ (Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aab6b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from deepctr_torch.callbacks import EarlyStopping\n",
    "\n",
    "class SteamConfig:\n",
    "    CSV_PATH = '../data/steam/deepfm_train_100k.csv'\n",
    "    MODEL_PATH = 'deepfm_steam_weights.pth'\n",
    "    \n",
    "    # --- ç½‘ç»œç»“æ„è®¾è®¡ (é’ˆå¯¹ 1.5k item / 100k data çš„é»„é‡‘æ¯”ä¾‹) ---\n",
    "    MAX_TAG_LEN = 5\n",
    "    EMBEDDING_DIM = 32       # 1500ä¸ªç‰©å“ï¼Œ32ç»´è¶³å¤Ÿè¡¨è¾¾ç‰¹å¾ï¼Œå¤ªå¤§å®¹æ˜“è¿‡æ‹Ÿåˆ\n",
    "    DNN_HIDDEN_UNITS = (128, 64) # ä¸¤å±‚è¶³å¤Ÿæ•æ‰é«˜é˜¶ç‰¹å¾ï¼Œä¸ç”¨å¤ªæ·±\n",
    "    DNN_DROPOUT = 0.5        # æ•°æ®é‡å°‘ï¼ŒDropout å¼€å¤§ç‚¹(0.5)é˜²æ­¢æ­»è®°ç¡¬èƒŒ\n",
    "    \n",
    "    # --- è®­ç»ƒå‚æ•° ---\n",
    "    BATCH_SIZE = 256         # ç¨å¾®è°ƒå° Batch Sizeï¼Œæœ‰åŠ©äºæ¨¡å‹è·³å‡ºå±€éƒ¨æœ€ä¼˜è§£ï¼Œå­¦å¾—æ›´ç»†\n",
    "    EPOCHS = 50              # è®¾ç½®å¤§ä¸€ç‚¹ï¼Œé  EarlyStopping æ¥è‡ªåŠ¨åœ\n",
    "    LEARNING_RATE = 0.001    # Adam é»˜è®¤å€¼ï¼Œé€šå¸¸ä¸ç”¨æ”¹\n",
    "    DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "cfg = SteamConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014d64d5",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-12-15T13:57:54.839048Z",
     "iopub.status.busy": "2025-12-15T13:57:54.838827Z",
     "iopub.status.idle": "2025-12-15T13:57:57.771390Z",
     "shell.execute_reply": "2025-12-15T13:57:57.770778Z",
     "shell.execute_reply.started": "2025-12-15T13:57:54.839031Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Steam data from: ../data/steam/train_data_Hardcore_Gamer.csv ...\n",
      "Compressed Max Tag ID (Vocabulary Size): 296\n",
      "Detected Max Tag ID: 296\n",
      "ğŸš€ ä½¿ç”¨è®¾å¤‡: cuda\n",
      "cuda\n",
      "Train on 400 samples, validate on 100 samples, 7 steps per epoch\n",
      "Epoch 1/100\n",
      "0s - loss:  0.6793\n",
      "Epoch 2/100\n",
      "0s - loss:  0.6288\n",
      "Epoch 3/100\n",
      "0s - loss:  0.5850\n",
      "Epoch 4/100\n",
      "0s - loss:  0.5360\n",
      "Epoch 5/100\n",
      "0s - loss:  0.4781\n",
      "Epoch 6/100\n",
      "0s - loss:  0.4307\n",
      "Epoch 7/100\n",
      "0s - loss:  0.3929\n",
      "Epoch 8/100\n",
      "0s - loss:  0.3657\n",
      "Epoch 9/100\n",
      "0s - loss:  0.3397\n",
      "Epoch 10/100\n",
      "0s - loss:  0.3081\n",
      "Epoch 11/100\n",
      "0s - loss:  0.2746\n",
      "Epoch 12/100\n",
      "0s - loss:  0.2393\n",
      "Epoch 13/100\n",
      "0s - loss:  0.2073\n",
      "Epoch 14/100\n",
      "0s - loss:  0.1795\n",
      "Epoch 15/100\n",
      "0s - loss:  0.1579\n",
      "Epoch 16/100\n",
      "0s - loss:  0.1413\n",
      "Epoch 17/100\n",
      "0s - loss:  0.1303\n",
      "Epoch 18/100\n",
      "0s - loss:  0.1219\n",
      "Epoch 19/100\n",
      "0s - loss:  0.1152\n",
      "Epoch 20/100\n",
      "0s - loss:  0.1084\n",
      "Epoch 21/100\n",
      "0s - loss:  0.1026\n",
      "Epoch 22/100\n",
      "0s - loss:  0.0964\n",
      "Epoch 23/100\n",
      "0s - loss:  0.0903\n",
      "Epoch 24/100\n",
      "0s - loss:  0.0838\n",
      "Epoch 25/100\n",
      "0s - loss:  0.0775\n",
      "Epoch 26/100\n",
      "0s - loss:  0.0713\n",
      "Epoch 27/100\n",
      "0s - loss:  0.0652\n",
      "Epoch 28/100\n",
      "0s - loss:  0.0595\n",
      "Epoch 29/100\n",
      "0s - loss:  0.0542\n",
      "Epoch 30/100\n",
      "0s - loss:  0.0490\n",
      "Epoch 31/100\n",
      "0s - loss:  0.0442\n",
      "Epoch 32/100\n",
      "0s - loss:  0.0400\n",
      "Epoch 33/100\n",
      "0s - loss:  0.0360\n",
      "Epoch 34/100\n",
      "0s - loss:  0.0325\n",
      "Epoch 35/100\n",
      "0s - loss:  0.0294\n",
      "Epoch 36/100\n",
      "0s - loss:  0.0265\n",
      "Epoch 37/100\n",
      "0s - loss:  0.0242\n",
      "Epoch 38/100\n",
      "0s - loss:  0.0219\n",
      "Epoch 39/100\n",
      "0s - loss:  0.0198\n",
      "Epoch 40/100\n",
      "0s - loss:  0.0181\n",
      "Epoch 41/100\n",
      "0s - loss:  0.0165\n",
      "Epoch 42/100\n",
      "0s - loss:  0.0152\n",
      "Epoch 43/100\n",
      "0s - loss:  0.0139\n",
      "Epoch 44/100\n",
      "0s - loss:  0.0128\n",
      "Epoch 45/100\n",
      "0s - loss:  0.0119\n",
      "Epoch 46/100\n",
      "0s - loss:  0.0110\n",
      "Epoch 47/100\n",
      "0s - loss:  0.0103\n",
      "Epoch 48/100\n",
      "0s - loss:  0.0096\n",
      "Epoch 49/100\n",
      "0s - loss:  0.0089\n",
      "Epoch 50/100\n",
      "0s - loss:  0.0084\n",
      "Epoch 51/100\n",
      "0s - loss:  0.0078\n",
      "Epoch 52/100\n",
      "0s - loss:  0.0074\n",
      "Epoch 53/100\n",
      "0s - loss:  0.0069\n",
      "Epoch 54/100\n",
      "0s - loss:  0.0065\n",
      "Epoch 55/100\n",
      "0s - loss:  0.0062\n",
      "Epoch 56/100\n",
      "0s - loss:  0.0058\n",
      "Epoch 57/100\n",
      "0s - loss:  0.0055\n",
      "Epoch 58/100\n",
      "0s - loss:  0.0053\n",
      "Epoch 59/100\n",
      "0s - loss:  0.0050\n",
      "Epoch 60/100\n",
      "0s - loss:  0.0048\n",
      "Epoch 61/100\n",
      "0s - loss:  0.0045\n",
      "Epoch 62/100\n",
      "0s - loss:  0.0043\n",
      "Epoch 63/100\n",
      "0s - loss:  0.0041\n",
      "Epoch 64/100\n",
      "0s - loss:  0.0039\n",
      "Epoch 65/100\n",
      "0s - loss:  0.0038\n",
      "Epoch 66/100\n",
      "0s - loss:  0.0036\n",
      "Epoch 67/100\n",
      "0s - loss:  0.0035\n",
      "Epoch 68/100\n",
      "0s - loss:  0.0033\n",
      "Epoch 69/100\n",
      "0s - loss:  0.0032\n",
      "Epoch 70/100\n",
      "0s - loss:  0.0031\n",
      "Epoch 71/100\n",
      "0s - loss:  0.0030\n",
      "Epoch 72/100\n",
      "0s - loss:  0.0028\n",
      "Epoch 73/100\n",
      "0s - loss:  0.0027\n",
      "Epoch 74/100\n",
      "0s - loss:  0.0026\n",
      "Epoch 75/100\n",
      "0s - loss:  0.0026\n",
      "Epoch 76/100\n",
      "0s - loss:  0.0025\n",
      "Epoch 77/100\n",
      "0s - loss:  0.0024\n",
      "Epoch 78/100\n",
      "0s - loss:  0.0023\n",
      "Epoch 79/100\n",
      "0s - loss:  0.0022\n",
      "Epoch 80/100\n",
      "0s - loss:  0.0022\n",
      "Epoch 81/100\n",
      "0s - loss:  0.0021\n",
      "Epoch 82/100\n",
      "0s - loss:  0.0020\n",
      "Epoch 83/100\n",
      "0s - loss:  0.0020\n",
      "Epoch 84/100\n",
      "0s - loss:  0.0019\n",
      "Epoch 85/100\n",
      "0s - loss:  0.0018\n",
      "Epoch 86/100\n",
      "0s - loss:  0.0018\n",
      "Epoch 87/100\n",
      "0s - loss:  0.0017\n",
      "Epoch 88/100\n",
      "0s - loss:  0.0017\n",
      "Epoch 89/100\n",
      "0s - loss:  0.0016\n",
      "Epoch 90/100\n",
      "0s - loss:  0.0016\n",
      "Epoch 91/100\n",
      "0s - loss:  0.0016\n",
      "Epoch 92/100\n",
      "0s - loss:  0.0015\n",
      "Epoch 93/100\n",
      "0s - loss:  0.0015\n",
      "Epoch 94/100\n",
      "0s - loss:  0.0014\n",
      "Epoch 95/100\n",
      "0s - loss:  0.0014\n",
      "Epoch 96/100\n",
      "0s - loss:  0.0014\n",
      "Epoch 97/100\n",
      "0s - loss:  0.0013\n",
      "Epoch 98/100\n",
      "0s - loss:  0.0013\n",
      "Epoch 99/100\n",
      "0s - loss:  0.0013\n",
      "Epoch 100/100\n",
      "0s - loss:  0.0012\n",
      "ğŸ‰ Steam æ¨¡å‹è®­ç»ƒå®Œæˆï¼\n"
     ]
    }
   ],
   "source": [
    "# 1. åŠ è½½æ•°æ® (å¤ç”¨ä¹‹å‰çš„ load_steam_data å‡½æ•°)\n",
    "input_dict, linear_cols, dnn_cols, target, _ = load_steam_data(cfg.CSV_PATH, cfg)\n",
    "\n",
    "# 2. åˆå§‹åŒ–æ¨¡å‹\n",
    "model = DeepFM(linear_feature_columns=linear_cols, \n",
    "               dnn_feature_columns=dnn_cols, \n",
    "               task='binary', \n",
    "               dnn_hidden_units=cfg.DNN_HIDDEN_UNITS,\n",
    "               dnn_dropout=cfg.DNN_DROPOUT,\n",
    "               device=cfg.DEVICE)\n",
    "\n",
    "# 3. ç¼–è¯‘ (æ³¨æ„ metrics)\n",
    "model.compile(\"adam\", \"binary_crossentropy\", metrics=[\"binary_crossentropy\", \"auc\"])\n",
    "\n",
    "# 4. å®šä¹‰æ—©åœç­–ç•¥ (ç›‘æ§ val_lossï¼Œå¦‚æœ 3 è½®éƒ½ä¸ä¸‹é™äº†ï¼Œå°±åœæ­¢)\n",
    "# æ³¨æ„ï¼šDeepCTR-Torch çš„ EarlyStopping éœ€è¦æ‰‹åŠ¨è°ƒç”¨æˆ–è‡ªå·±å†™å›# 1. åŠ è½½æ•°æ® (å¤ç”¨ä¹‹å‰çš„ load_steam_data å‡½æ•°)\n",
    "input_dict, linear_cols, dnn_cols, target, _ = load_steam_data(cfg.CSV_PATH, cfg)\n",
    "\n",
    "# 2. åˆå§‹åŒ–æ¨¡å‹\n",
    "model = DeepFM(linear_feature_columns=linear_cols, \n",
    "               dnn_feature_columns=dnn_cols, \n",
    "               task='binary', \n",
    "               dnn_hidden_units=cfg.DNN_HIDDEN_UNITS,\n",
    "               dnn_dropout=cfg.DNN_DROPOUT,\n",
    "               device=cfg.DEVICE)\n",
    "\n",
    "# 3. ç¼–è¯‘ (æ³¨æ„ metrics)\n",
    "model.compile(\"adam\", \"binary_crossentropy\", metrics=[\"binary_crossentropy\", \"auc\"])\n",
    "\n",
    "# 4. å®šä¹‰æ—©åœç­–ç•¥ (ç›‘æ§ val_lossï¼Œå¦‚æœ 3 è½®éƒ½ä¸ä¸‹é™äº†ï¼Œå°±åœæ­¢)\n",
    "# æ³¨æ„ï¼šDeepCTR-Torch çš„ EarlyStopping éœ€è¦æ‰‹åŠ¨è°ƒç”¨æˆ–è‡ªå·±å†™å›è°ƒï¼Œ\n",
    "# è¿™é‡Œ deepctr_torch çš„ fit å¹¶ä¸ç›´æ¥æ”¯æŒ Keras é£æ ¼çš„ callbacks åˆ—è¡¨ï¼Œ\n",
    "# ä½†å®ƒè¿”å›çš„ history è¶³å¤Ÿæˆ‘ä»¬è¦ç”»å›¾äº†ã€‚æˆ‘ä»¬æ‰‹åŠ¨æ ¹æ® epoch è®¾å®šç®€å•çš„æ—©åœé€šå¸¸ä¹Ÿå¯ä»¥ï¼Œ\n",
    "# æˆ–è€…ç›´æ¥è·‘å®Œçœ‹æ›²çº¿ã€‚è¿™é‡Œä¸ºäº†ç®€å•ï¼Œæˆ‘ä»¬å…ˆè·‘å®Œçœ‹æ›²çº¿ã€‚\n",
    "\n",
    "print(f\"ğŸš€ å¼€å§‹è®­ç»ƒ... (Items: ~1500, Data: {len(target)})\")\n",
    "\n",
    "# 5. è®­ç»ƒå¹¶è·å–å†å²è®°å½•\n",
    "history = model.fit(input_dict, target, \n",
    "                    batch_size=cfg.BATCH_SIZE, \n",
    "                    epochs=cfg.EPOCHS, \n",
    "                    verbose=2, \n",
    "                    validation_split=0.2) # åˆ’ 20% åšéªŒè¯é›†\n",
    "\n",
    "# 6. ä¿å­˜æ¨¡å‹\n",
    "torch.save(model.state_dict(), cfg.MODEL_PATH)\n",
    "print(\"âœ… æ¨¡å‹ä¿å­˜å®Œæ¯•ã€‚\")\n",
    "\n",
    "# ==========================================\n",
    "# ğŸ“ˆ å…³é”®æ­¥éª¤ï¼šç»˜åˆ¶ Loss æ›²çº¿\n",
    "# ==========================================\n",
    "def plot_learning_curves(history):\n",
    "    # æå–æ•°æ®\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(1, len(loss) + 1)\n",
    "    \n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # ç»˜åˆ¶ Loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, loss, 'b-', label='Training Loss')\n",
    "    plt.plot(epochs, val_loss, 'r--', label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # å¦‚æœæœ‰ AUC æŒ‡æ ‡ä¹Ÿå¯ä»¥ç”»\n",
    "    if 'auc' in history.history:\n",
    "        auc = history.history['auc']\n",
    "        val_auc = history.history['val_auc']\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(epochs, auc, 'b-', label='Training AUC')\n",
    "        plt.plot(epochs, val_auc, 'r--', label='Validation AUC')\n",
    "        plt.title('Training and Validation AUC')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('AUC')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\nğŸ“Š æ­£åœ¨ç”Ÿæˆè®­ç»ƒæ›²çº¿...\")\n",
    "plot_learning_curves(history)è°ƒï¼Œ\n",
    "# è¿™é‡Œ deepctr_torch çš„ fit å¹¶ä¸ç›´æ¥æ”¯æŒ Keras é£æ ¼çš„ callbacks åˆ—è¡¨ï¼Œ\n",
    "# ä½†å®ƒè¿”å›çš„ history è¶³å¤Ÿæˆ‘ä»¬è¦ç”»å›¾äº†ã€‚æˆ‘ä»¬æ‰‹åŠ¨æ ¹æ® epoch è®¾å®šç®€å•çš„æ—©åœé€šå¸¸ä¹Ÿå¯ä»¥ï¼Œ\n",
    "# æˆ–è€…ç›´æ¥è·‘å®Œçœ‹æ›²çº¿ã€‚è¿™é‡Œä¸ºäº†ç®€å•ï¼Œæˆ‘ä»¬å…ˆè·‘å®Œçœ‹æ›²çº¿ã€‚\n",
    "\n",
    "print(f\"ğŸš€ å¼€å§‹è®­ç»ƒ... (Items: ~1500, Data: {len(target)})\")\n",
    "\n",
    "# 5. è®­ç»ƒå¹¶è·å–å†å²è®°å½•\n",
    "history = model.fit(input_dict, target, \n",
    "                    batch_size=cfg.BATCH_SIZE, \n",
    "                    epochs=cfg.EPOCHS, \n",
    "                    verbose=2, \n",
    "                    validation_split=0.2) # åˆ’ 20% åšéªŒè¯é›†\n",
    "\n",
    "# 6. ä¿å­˜æ¨¡å‹\n",
    "torch.save(model.state_dict(), cfg.MODEL_PATH)\n",
    "print(\"âœ… æ¨¡å‹ä¿å­˜å®Œæ¯•ã€‚\")\n",
    "\n",
    "# ==========================================\n",
    "# ğŸ“ˆ å…³é”®æ­¥éª¤ï¼šç»˜åˆ¶ Loss æ›²çº¿\n",
    "# ==========================================\n",
    "def plot_learning_curves(history):\n",
    "    # æå–æ•°æ®\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(1, len(loss) + 1)\n",
    "    \n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # ç»˜åˆ¶ Loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, loss, 'b-', label='Training Loss')\n",
    "    plt.plot(epochs, val_loss, 'r--', label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # å¦‚æœæœ‰ AUC æŒ‡æ ‡ä¹Ÿå¯ä»¥ç”»\n",
    "    if 'auc' in history.history:\n",
    "        auc = history.history['auc']\n",
    "        val_auc = history.history['val_auc']\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(epochs, auc, 'b-', label='Training AUC')\n",
    "        plt.plot(epochs, val_auc, 'r--', label='Validation AUC')\n",
    "        plt.title('Training and Validation AUC')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('AUC')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"\\nğŸ“Š æ­£åœ¨ç”Ÿæˆè®­ç»ƒæ›²çº¿...\")\n",
    "plot_learning_curves(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f53504",
   "metadata": {},
   "source": [
    "## åŠ è½½æƒé‡å¹¶å¯åŠ¨ API æœåŠ¡ (Loading & Serving)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64213e47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T13:56:56.166452Z",
     "iopub.status.busy": "2025-12-15T13:56:56.166235Z",
     "iopub.status.idle": "2025-12-15T13:56:56.317924Z",
     "shell.execute_reply": "2025-12-15T13:56:56.316960Z",
     "shell.execute_reply.started": "2025-12-15T13:56:56.166435Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ æ­£åœ¨åˆå§‹åŒ–æœåŠ¡ï¼Œé‡æ–°æ„å»ºæ¨¡å‹ç»“æ„...\n",
      "Loading Steam data from: ../data/steam/train_data_Hardcore_Gamer.csv ...\n",
      "Compressed Max Tag ID (Vocabulary Size): 296\n",
      "Detected Max Tag ID: 296\n",
      "âœ… Steam æ¨¡å‹åŠ è½½æˆåŠŸï¼\n",
      "ğŸš€ æœåŠ¡å·²å¯åŠ¨ï¼ç›‘å¬ç«¯å£ 5000...\n",
      "ä½ å¯ä»¥è¿è¡Œä¸‹ä¸€ä¸ª Cell æ¥æµ‹è¯•æ¥å£ã€‚\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://10.250.145.130:5000\n",
      "Press CTRL+C to quit\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import threading\n",
    "from flask import Flask, request, jsonify\n",
    "from deepctr_torch.models import DeepFM\n",
    "\n",
    "# 1. å‡†å¤‡ç¯å¢ƒ\n",
    "print(\"ğŸ”„ æ­£åœ¨åˆå§‹åŒ–æœåŠ¡ï¼Œé‡æ–°æ„å»ºæ¨¡å‹ç»“æ„...\")\n",
    "\n",
    "# ä¸ºäº†è·å– Feature Columns ç»“æ„ï¼Œæˆ‘ä»¬éœ€è¦å†è°ƒç”¨ä¸€æ¬¡æ•°æ®åŠ è½½å‡½æ•°\n",
    "# (æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬å¤ç”¨ä¹‹å‰çš„ load_steam_dataï¼Œè™½ç„¶æ•ˆç‡ç•¥ä½ä½†èƒ½ä¿è¯ç»“æ„ç»å¯¹ä¸€è‡´)\n",
    "_, linear_cols, dnn_cols, _, df_raw = load_steam_data(cfg.CSV_PATH, cfg)\n",
    "\n",
    "# 2. åˆå§‹åŒ–ç©ºæ¨¡å‹ (å…³é”®ï¼šä½¿ç”¨ cfg.DNN_HIDDEN_UNITS)\n",
    "service_model = DeepFM(linear_feature_columns=linear_cols, \n",
    "                       dnn_feature_columns=dnn_cols, \n",
    "                       task='binary', \n",
    "                       dnn_hidden_units=cfg.DNN_HIDDEN_UNITS, # âœ… ç¡®ä¿ä¸è®­ç»ƒä¸€è‡´\n",
    "                       dnn_dropout=cfg.DNN_DROPOUT,\n",
    "                       device=cfg.DEVICE)\n",
    "\n",
    "# 3. åŠ è½½æƒé‡\n",
    "try:\n",
    "    service_model.load_state_dict(torch.load(cfg.MODEL_PATH, map_location=cfg.DEVICE))\n",
    "    service_model.eval() # åˆ‡æ¢åˆ°è¯„ä¼°æ¨¡å¼\n",
    "    print(\"âœ… æ¨¡å‹æƒé‡åŠ è½½æˆåŠŸï¼Ready to serve.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"âŒ æœªæ‰¾åˆ°æƒé‡æ–‡ä»¶ {cfg.MODEL_PATH}ï¼Œè¯·å…ˆè¿è¡Œ Cell 4 è¿›è¡Œè®­ç»ƒã€‚\")\n",
    "\n",
    "# ================= æ­å»º Flask API (Notebook ç‰ˆ) =================\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/recommend', methods=['POST'])\n",
    "def recommend_api():\n",
    "    try:\n",
    "        req = request.json\n",
    "        top_k = req.get('top_k', 3)\n",
    "        \n",
    "        # --- ç®€å•å…¨é‡æ£€ç´¢é€»è¾‘ ---\n",
    "        # 1. æ„é€  Input (ç›´æ¥ä½¿ç”¨å†…å­˜ä¸­çš„ df_raw å¤„ç†ç»“æœ)\n",
    "        # æ³¨æ„ï¼šå®é™…ç”Ÿäº§ä¸­åº”æŠŠ pad_sequences å°è£…å¥½ç»™å•æ¡æ•°æ®ç”¨ï¼Œè¿™é‡Œä¸ºäº†æ¼”ç¤ºæ–¹ä¾¿ç›´æ¥æ‰¹é‡é¢„æµ‹\n",
    "        tags_padded = pad_sequences(list(df_raw['tags_list']), maxlen=cfg.MAX_TAG_LEN, value=0)\n",
    "        \n",
    "        input_dict = {\n",
    "            'item_id_idx': df_raw['item_id_idx'].values,\n",
    "            'price_norm': df_raw['price_norm'].values,\n",
    "            'tags': tags_padded\n",
    "        }\n",
    "        \n",
    "        # 2. é¢„æµ‹\n",
    "        with torch.no_grad():\n",
    "            pred_scores = service_model.predict(input_dict, batch_size=4096)\n",
    "            \n",
    "        # 3. æ’åº\n",
    "        temp_df = df_raw.copy()\n",
    "        temp_df['score'] = pred_scores\n",
    "        top_items = temp_df.sort_values(by='score', ascending=False).head(top_k)\n",
    "        \n",
    "        # 4. æ ¼å¼åŒ–\n",
    "        results = []\n",
    "        for _, row in top_items.iterrows():\n",
    "            results.append({\n",
    "                \"id\": str(row['item_id']),\n",
    "                \"title\": row['title'],\n",
    "                \"score\": float(row['score']),\n",
    "                \"tags\": row.get('tag_names', 'Unknown')\n",
    "            })\n",
    "            \n",
    "        return jsonify({\"code\": 200, \"data\": results})\n",
    "        \n",
    "    except Exception as e:\n",
    "        return jsonify({\"code\": 500, \"error\": str(e)})\n",
    "\n",
    "# ================= å¯åŠ¨åå°çº¿ç¨‹ =================\n",
    "def run_flask():\n",
    "    # ç«¯å£è®¾ä¸º 5000\n",
    "    app.run(host='0.0.0.0', port=5000, debug=False, use_reloader=False)\n",
    "\n",
    "# é¿å…é‡å¤å¯åŠ¨\n",
    "if 'flask_thread' not in locals() or not flask_thread.is_alive():\n",
    "    flask_thread = threading.Thread(target=run_flask)\n",
    "    flask_thread.daemon = True\n",
    "    flask_thread.start()\n",
    "    print(\"ğŸš€ æœåŠ¡å·²åœ¨åå°å¯åŠ¨ï¼ç›‘å¬ç«¯å£ 5000...\")\n",
    "else:\n",
    "    print(\"âš ï¸ æœåŠ¡å·²ç»åœ¨è¿è¡Œä¸­ï¼Œæ— éœ€å†æ¬¡å¯åŠ¨ã€‚\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f8e077",
   "metadata": {},
   "source": [
    "## æµ‹è¯•æœåŠ¡ (Client Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0dcfde8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T13:57:03.258057Z",
     "iopub.status.busy": "2025-12-15T13:57:03.257835Z",
     "iopub.status.idle": "2025-12-15T13:57:05.277965Z",
     "shell.execute_reply": "2025-12-15T13:57:05.277252Z",
     "shell.execute_reply.started": "2025-12-15T13:57:03.258042Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [15/Dec/2025 21:57:05] \"POST /recommend HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¡ è¯·æ±‚ Steam æ¨è...\n",
      "Steam Response: {'code': 200, 'data': [{'cover': 'https://shared.fastly.steamstatic.com/store_item_assets/steam/apps/3606480/bbdbbfce8a336864a974ee49419dabb6ccce5793/capsule_231x87_schinese.jpg?t=1765589367', 'id': '3606480', 'score': 0.9585115313529968, 'tags': 'åŠ¨ä½œ,å°„å‡»,è‚‰é¸½', 'title': 'Call of DutyÂ®: Black Ops 7'}, {'cover': 'https://shared.fastly.steamstatic.com/store_item_assets/steam/apps/1466860/capsule_231x87.jpg?t=1762295217', 'id': '1466860', 'score': 0.9539361000061035, 'tags': 'å¤šäºº', 'title': 'Age of Empires IV: Anniversary Edition'}], 'type': 'steam'}\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "\n",
    "# ç­‰å¾…æœåŠ¡å°±ç»ª\n",
    "time.sleep(1)\n",
    "\n",
    "url = \"http://127.0.0.1:5000/recommend\"\n",
    "\n",
    "print(f\"ğŸ“¡ å‘é€è¯·æ±‚åˆ°: {url} ...\")\n",
    "payload = {\n",
    "    \"type\": \"steam\", \n",
    "    \"top_k\": 3\n",
    "}\n",
    "\n",
    "try:\n",
    "    resp = requests.post(url, json=payload, timeout=5)\n",
    "    if resp.status_code == 200:\n",
    "        print(\"\\nâœ… æ¨èæˆåŠŸï¼ç»“æœå¦‚ä¸‹ï¼š\")\n",
    "        data = resp.json().get('data', [])\n",
    "        for item in data:\n",
    "            print(f\"  - [{item['score']:.4f}] {item['title']} ({item['tags']})\")\n",
    "    else:\n",
    "        print(f\"âŒ è¯·æ±‚å¤±è´¥: {resp.text}\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ è¿æ¥é”™è¯¯: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
