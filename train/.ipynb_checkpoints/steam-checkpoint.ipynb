{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "198453dc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Steam æ•°æ®åŠ è½½ä¸é¢„å¤„ç†\n",
    "\n",
    "æ ¸å¿ƒé€»è¾‘ï¼š\n",
    "\n",
    "1. å¤„ç† tags_list: å®ƒæ˜¯å­—ç¬¦ä¸²æ ¼å¼çš„åˆ—è¡¨ \"[1663, 1774]\"ï¼Œéœ€è¦è¿˜åŸå¹¶è¡¥é½é•¿åº¦ã€‚\n",
    "\n",
    "2. å¤„ç† price: å½’ä¸€åŒ–ã€‚\n",
    "\n",
    "3. å¤„ç† item_id: å»ºç«‹ç´¢å¼•æ˜ å°„ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12086bde-d748-4e5f-9fdf-3ebb9832a32c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T13:52:22.776211Z",
     "iopub.status.busy": "2025-12-15T13:52:22.776092Z",
     "iopub.status.idle": "2025-12-15T13:52:26.841981Z",
     "shell.execute_reply": "2025-12-15T13:52:26.841331Z",
     "shell.execute_reply.started": "2025-12-15T13:52:22.776197Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.cloud.aliyuncs.com/pypi/simple\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/site-packages (2.9.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/site-packages (2.3.5)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/site-packages (1.7.2)\n",
      "Requirement already satisfied: deepctr-torch in /usr/local/lib/python3.11/site-packages (0.2.9)\n",
      "Requirement already satisfied: flask in /usr/local/lib/python3.11/site-packages (3.1.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/site-packages (2.32.5)\n",
      "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/site-packages (7.5.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.11/site-packages (from torch) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.11/site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.11/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.11/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.11/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.11/site-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.11/site-packages (from torch) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.11/site-packages (from torch) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.11/site-packages (from torch) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.11/site-packages (from torch) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.11/site-packages (from torch) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.11/site-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.11/site-packages (from torch) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.11/site-packages (from torch) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.11/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.11/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.11/site-packages (from torch) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.1 in /usr/local/lib/python3.11/site-packages (from torch) (3.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/site-packages (from pandas) (2025.3)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.11/site-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/site-packages (from deepctr-torch) (4.67.1)\n",
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/site-packages (from deepctr-torch) (2.20.0)\n",
      "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/site-packages (from flask) (1.9.0)\n",
      "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/site-packages (from flask) (8.2.1)\n",
      "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/site-packages (from flask) (2.2.0)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/site-packages (from flask) (3.0.3)\n",
      "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.11/site-packages (from flask) (3.1.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/site-packages (from requests) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/site-packages (from requests) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/site-packages (from requests) (2.6.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/site-packages (from requests) (2025.11.12)\n",
      "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/site-packages (from pyngrok) (6.0.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/site-packages (from tensorflow->deepctr-torch) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/site-packages (from tensorflow->deepctr-torch) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/site-packages (from tensorflow->deepctr-torch) (25.9.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/site-packages (from tensorflow->deepctr-torch) (0.7.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in /usr/local/lib/python3.11/site-packages (from tensorflow->deepctr-torch) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/site-packages (from tensorflow->deepctr-torch) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in /usr/local/lib/python3.11/site-packages (from tensorflow->deepctr-torch) (3.4.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/site-packages (from tensorflow->deepctr-torch) (25.0)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in /usr/local/lib/python3.11/site-packages (from tensorflow->deepctr-torch) (6.33.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/site-packages (from tensorflow->deepctr-torch) (65.5.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/site-packages (from tensorflow->deepctr-torch) (3.2.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/site-packages (from tensorflow->deepctr-torch) (2.0.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/site-packages (from tensorflow->deepctr-torch) (1.76.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in /usr/local/lib/python3.11/site-packages (from tensorflow->deepctr-torch) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in /usr/local/lib/python3.11/site-packages (from tensorflow->deepctr-torch) (3.12.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/site-packages (from tensorflow->deepctr-torch) (3.15.1)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.11/site-packages (from tensorflow->deepctr-torch) (0.5.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow->deepctr-torch) (0.45.1)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.11/site-packages (from keras>=3.10.0->tensorflow->deepctr-torch) (14.2.0)\n",
      "Requirement already satisfied: namex in /usr/local/lib/python3.11/site-packages (from keras>=3.10.0->tensorflow->deepctr-torch) (0.1.0)\n",
      "Requirement already satisfied: optree in /usr/local/lib/python3.11/site-packages (from keras>=3.10.0->tensorflow->deepctr-torch) (0.18.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/site-packages (from tensorboard~=2.20.0->tensorflow->deepctr-torch) (3.10)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.11/site-packages (from tensorboard~=2.20.0->tensorflow->deepctr-torch) (12.0.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/site-packages (from tensorboard~=2.20.0->tensorflow->deepctr-torch) (0.7.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/site-packages (from rich->keras>=3.10.0->tensorflow->deepctr-torch) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/site-packages (from rich->keras>=3.10.0->tensorflow->deepctr-torch) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow->deepctr-torch) (0.1.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# ğŸ® å®‰è£… Steam æ¨èç³»ç»Ÿæ‰€éœ€çš„åŒ…ï¼ˆå·²ç§»é™¤ TensorFlow ä¾èµ–ï¼‰\n",
    "!pip install torch pandas numpy scikit-learn deepctr-torch flask requests pyngrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1545474",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2025-12-15T13:52:26.842887Z",
     "iopub.status.busy": "2025-12-15T13:52:26.842697Z",
     "iopub.status.idle": "2025-12-15T13:52:30.648526Z",
     "shell.execute_reply": "2025-12-15T13:52:30.647839Z",
     "shell.execute_reply.started": "2025-12-15T13:52:26.842871Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-15 21:52:28.847640: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-15 21:52:28.896481: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-12-15 21:52:30.200857: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# ğŸ® Steam æ•°æ®åŠ è½½å™¨ (Data Loader)\n",
    "# ==========================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from deepctr_torch.inputs import SparseFeat, DenseFeat, VarLenSparseFeat\n",
    "\n",
    "def pad_sequences(sequences, maxlen, value=0):\n",
    "    \"\"\"\n",
    "    æ‰‹åŠ¨å®ç°åè¡¥é½ï¼ˆpadding='post'ï¼‰å’Œåæˆªæ–­ï¼ˆtruncating='post'ï¼‰\n",
    "    \"\"\"\n",
    "    result = np.full((len(sequences), maxlen), value, dtype=np.int32)\n",
    "    for i, seq in enumerate(sequences):\n",
    "        if len(seq) > 0:\n",
    "            # å–åºåˆ—å’Œmaxlençš„æœ€å°å€¼è¿›è¡Œå¡«å……\n",
    "            trunc = seq[:maxlen]\n",
    "            result[i, :len(trunc)] = trunc\n",
    "    return result\n",
    "\n",
    "def load_steam_data(csv_path):\n",
    "    print(f\"Loading Steam data from: {csv_path} ...\")\n",
    "    data = pd.read_csv(csv_path)\n",
    "    # --- æ‰“ä¹±æ•°æ®é¡ºåºï¼Œé˜²æ­¢èšé›† ---\n",
    "    data = data.sample(frac=1, random_state=2024).reset_index(drop=True)\n",
    "    \n",
    "    # 1. ã€å…³é”®ã€‘å°†å­—ç¬¦ä¸²æ ¼å¼çš„ list è¿˜åŸä¸ºçœŸæ­£çš„ list\n",
    "    # CSVé‡Œå­˜çš„æ˜¯ \"[1663, 1774]\" (String)ï¼Œæ¨¡å‹è¦çš„æ˜¯ [1663, 1774] (List)\n",
    "    data['tags_list'] = data['tags_list'].apply(lambda x: ast.literal_eval(x))\n",
    "    \n",
    "    # --- ä¼˜åŒ–ï¼šå¯¹ Tags è¿›è¡Œç»Ÿä¸€ç¼–ç  ---\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    all_tags_in_data = [tag for sublist in data['tags_list'] for tag in sublist]\n",
    "    tag_lbe = LabelEncoder()\n",
    "    # æ‹Ÿåˆæ‰€æœ‰å‡ºç°çš„æ ‡ç­¾\n",
    "    tag_lbe.fit(all_tags_in_data)\n",
    "    \n",
    "    # å°†åŸå§‹æ ‡ç­¾è½¬æ¢ä¸ºè¿ç»­ç´¢å¼• (ä» 1 å¼€å§‹ï¼Œä¿ç•™ 0 ç»™ Padding)\n",
    "    data['tags_list'] = data['tags_list'].apply(\n",
    "        lambda x: [i + 1 for i in tag_lbe.transform(x)] if len(x) > 0 else []\n",
    "    )\n",
    "    \n",
    "    # ç°åœ¨çš„è¯è¡¨å¤§å°åªéœ€è¦æ˜¯å®é™…ä¸åŒæ ‡ç­¾çš„æ•°é‡ + 1\n",
    "    MAX_TAG_ID = len(tag_lbe.classes_) + 1 \n",
    "    print(f\"Compressed Max Tag ID (Vocabulary Size): {MAX_TAG_ID}\")\n",
    "    # -------------------------------\n",
    "\n",
    "    # 2. ç‰¹å¾ç¼–ç  (Encoding)\n",
    "    # Item ID: ç¦»æ•£ç‰¹å¾ -> 0, 1, 2...\n",
    "    lbe = LabelEncoder()\n",
    "    data['item_id_idx'] = lbe.fit_transform(data['item_id'])\n",
    "    \n",
    "    # Price: è¿ç»­ç‰¹å¾ -> 0.0 ~ 1.0\n",
    "    mms = MinMaxScaler(feature_range=(0, 1))\n",
    "    data['price_norm'] = mms.fit_transform(data[['price']])\n",
    "\n",
    "    # 3. åºåˆ—ç‰¹å¾å¤„ç† (Padding)\n",
    "    # DeepFM è¦æ±‚ tags è¾“å…¥å¿…é¡»å®šé•¿ã€‚å‡è®¾æœ€å¤§é•¿åº¦ä¸º 5ã€‚\n",
    "    # [1663, 1774] -> [1663, 1774, 0, 0, 0]\n",
    "    MAX_TAG_LEN = 5\n",
    "\n",
    "    all_tags = []\n",
    "    for tags in data['tags_list']:\n",
    "        all_tags.extend(tags)\n",
    "    # è¯è¡¨å¤§å° = æœ€å¤§ID + 1 (è€ƒè™‘åˆ°ç´¢å¼•ä»0å¼€å§‹)\n",
    "    MAX_TAG_ID = int(max(all_tags)) + 1 if len(all_tags) > 0 else 1\n",
    "    print(f\"Detected Max Tag ID: {MAX_TAG_ID}\")\n",
    "\n",
    "    tags_list = list(data['tags_list'])\n",
    "    # padding='post' è¡¨ç¤ºåœ¨åé¢è¡¥0\n",
    "    tags_padded = pad_sequences(tags_list, maxlen=MAX_TAG_LEN, value=0)\n",
    "\n",
    "    # 4. å®šä¹‰ DeepFM ç‰¹å¾é…ç½® (Feature Columns)\n",
    "    # å‘Šè¯‰æ¨¡å‹ï¼šå“ªäº›æ˜¯ç¦»æ•£çš„ï¼Œå“ªäº›æ˜¯è¿ç»­çš„ï¼Œå“ªäº›æ˜¯å˜é•¿çš„\n",
    "    fixlen_feature_columns = [\n",
    "        SparseFeat(name='item_id_idx', vocabulary_size=data['item_id_idx'].max() + 1, embedding_dim=16),\n",
    "        DenseFeat(name='price_norm', dimension=1)\n",
    "    ]\n",
    "    \n",
    "    varlen_feature_columns = [\n",
    "        VarLenSparseFeat(\n",
    "            SparseFeat('tags', vocabulary_size=MAX_TAG_ID, embedding_dim=16),\n",
    "            maxlen=MAX_TAG_LEN, combiner='mean', length_name=None\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    linear_feature_columns = fixlen_feature_columns + varlen_feature_columns\n",
    "    dnn_feature_columns = fixlen_feature_columns + varlen_feature_columns\n",
    "\n",
    "    # 5. ç»„è£…è¾“å…¥å­—å…¸ (Input Dict)\n",
    "    model_input = {\n",
    "        'item_id_idx': data['item_id_idx'].values,\n",
    "        'price_norm': data['price_norm'].values,\n",
    "        'tags': tags_padded\n",
    "    }\n",
    "    \n",
    "    # Label\n",
    "    target = data['label'].values\n",
    "    \n",
    "    return model_input, linear_feature_columns, dnn_feature_columns, target\n",
    "\n",
    "# --- æµ‹è¯•è¿è¡Œ ---\n",
    "# å‡è®¾ä½ ä¿å­˜çš„æ–‡ä»¶åæ˜¯ steam_data.csv\n",
    "# steam_input, steam_linear, steam_dnn, steam_y = load_steam_data('steam_data.csv')\n",
    "# print(\"Steam Input Shapes:\", {k: v.shape for k, v in steam_input.items()})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ce3e68",
   "metadata": {},
   "source": [
    "## Steam æ¨¡å‹è®­ç»ƒ (Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "014d64d5",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-12-15T13:57:54.839048Z",
     "iopub.status.busy": "2025-12-15T13:57:54.838827Z",
     "iopub.status.idle": "2025-12-15T13:57:57.771390Z",
     "shell.execute_reply": "2025-12-15T13:57:57.770778Z",
     "shell.execute_reply.started": "2025-12-15T13:57:54.839031Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Steam data from: ../data/steam/train_data_Hardcore_Gamer.csv ...\n",
      "Compressed Max Tag ID (Vocabulary Size): 296\n",
      "Detected Max Tag ID: 296\n",
      "ğŸš€ ä½¿ç”¨è®¾å¤‡: cuda\n",
      "cuda\n",
      "Train on 400 samples, validate on 100 samples, 7 steps per epoch\n",
      "Epoch 1/100\n",
      "0s - loss:  0.6793\n",
      "Epoch 2/100\n",
      "0s - loss:  0.6288\n",
      "Epoch 3/100\n",
      "0s - loss:  0.5850\n",
      "Epoch 4/100\n",
      "0s - loss:  0.5360\n",
      "Epoch 5/100\n",
      "0s - loss:  0.4781\n",
      "Epoch 6/100\n",
      "0s - loss:  0.4307\n",
      "Epoch 7/100\n",
      "0s - loss:  0.3929\n",
      "Epoch 8/100\n",
      "0s - loss:  0.3657\n",
      "Epoch 9/100\n",
      "0s - loss:  0.3397\n",
      "Epoch 10/100\n",
      "0s - loss:  0.3081\n",
      "Epoch 11/100\n",
      "0s - loss:  0.2746\n",
      "Epoch 12/100\n",
      "0s - loss:  0.2393\n",
      "Epoch 13/100\n",
      "0s - loss:  0.2073\n",
      "Epoch 14/100\n",
      "0s - loss:  0.1795\n",
      "Epoch 15/100\n",
      "0s - loss:  0.1579\n",
      "Epoch 16/100\n",
      "0s - loss:  0.1413\n",
      "Epoch 17/100\n",
      "0s - loss:  0.1303\n",
      "Epoch 18/100\n",
      "0s - loss:  0.1219\n",
      "Epoch 19/100\n",
      "0s - loss:  0.1152\n",
      "Epoch 20/100\n",
      "0s - loss:  0.1084\n",
      "Epoch 21/100\n",
      "0s - loss:  0.1026\n",
      "Epoch 22/100\n",
      "0s - loss:  0.0964\n",
      "Epoch 23/100\n",
      "0s - loss:  0.0903\n",
      "Epoch 24/100\n",
      "0s - loss:  0.0838\n",
      "Epoch 25/100\n",
      "0s - loss:  0.0775\n",
      "Epoch 26/100\n",
      "0s - loss:  0.0713\n",
      "Epoch 27/100\n",
      "0s - loss:  0.0652\n",
      "Epoch 28/100\n",
      "0s - loss:  0.0595\n",
      "Epoch 29/100\n",
      "0s - loss:  0.0542\n",
      "Epoch 30/100\n",
      "0s - loss:  0.0490\n",
      "Epoch 31/100\n",
      "0s - loss:  0.0442\n",
      "Epoch 32/100\n",
      "0s - loss:  0.0400\n",
      "Epoch 33/100\n",
      "0s - loss:  0.0360\n",
      "Epoch 34/100\n",
      "0s - loss:  0.0325\n",
      "Epoch 35/100\n",
      "0s - loss:  0.0294\n",
      "Epoch 36/100\n",
      "0s - loss:  0.0265\n",
      "Epoch 37/100\n",
      "0s - loss:  0.0242\n",
      "Epoch 38/100\n",
      "0s - loss:  0.0219\n",
      "Epoch 39/100\n",
      "0s - loss:  0.0198\n",
      "Epoch 40/100\n",
      "0s - loss:  0.0181\n",
      "Epoch 41/100\n",
      "0s - loss:  0.0165\n",
      "Epoch 42/100\n",
      "0s - loss:  0.0152\n",
      "Epoch 43/100\n",
      "0s - loss:  0.0139\n",
      "Epoch 44/100\n",
      "0s - loss:  0.0128\n",
      "Epoch 45/100\n",
      "0s - loss:  0.0119\n",
      "Epoch 46/100\n",
      "0s - loss:  0.0110\n",
      "Epoch 47/100\n",
      "0s - loss:  0.0103\n",
      "Epoch 48/100\n",
      "0s - loss:  0.0096\n",
      "Epoch 49/100\n",
      "0s - loss:  0.0089\n",
      "Epoch 50/100\n",
      "0s - loss:  0.0084\n",
      "Epoch 51/100\n",
      "0s - loss:  0.0078\n",
      "Epoch 52/100\n",
      "0s - loss:  0.0074\n",
      "Epoch 53/100\n",
      "0s - loss:  0.0069\n",
      "Epoch 54/100\n",
      "0s - loss:  0.0065\n",
      "Epoch 55/100\n",
      "0s - loss:  0.0062\n",
      "Epoch 56/100\n",
      "0s - loss:  0.0058\n",
      "Epoch 57/100\n",
      "0s - loss:  0.0055\n",
      "Epoch 58/100\n",
      "0s - loss:  0.0053\n",
      "Epoch 59/100\n",
      "0s - loss:  0.0050\n",
      "Epoch 60/100\n",
      "0s - loss:  0.0048\n",
      "Epoch 61/100\n",
      "0s - loss:  0.0045\n",
      "Epoch 62/100\n",
      "0s - loss:  0.0043\n",
      "Epoch 63/100\n",
      "0s - loss:  0.0041\n",
      "Epoch 64/100\n",
      "0s - loss:  0.0039\n",
      "Epoch 65/100\n",
      "0s - loss:  0.0038\n",
      "Epoch 66/100\n",
      "0s - loss:  0.0036\n",
      "Epoch 67/100\n",
      "0s - loss:  0.0035\n",
      "Epoch 68/100\n",
      "0s - loss:  0.0033\n",
      "Epoch 69/100\n",
      "0s - loss:  0.0032\n",
      "Epoch 70/100\n",
      "0s - loss:  0.0031\n",
      "Epoch 71/100\n",
      "0s - loss:  0.0030\n",
      "Epoch 72/100\n",
      "0s - loss:  0.0028\n",
      "Epoch 73/100\n",
      "0s - loss:  0.0027\n",
      "Epoch 74/100\n",
      "0s - loss:  0.0026\n",
      "Epoch 75/100\n",
      "0s - loss:  0.0026\n",
      "Epoch 76/100\n",
      "0s - loss:  0.0025\n",
      "Epoch 77/100\n",
      "0s - loss:  0.0024\n",
      "Epoch 78/100\n",
      "0s - loss:  0.0023\n",
      "Epoch 79/100\n",
      "0s - loss:  0.0022\n",
      "Epoch 80/100\n",
      "0s - loss:  0.0022\n",
      "Epoch 81/100\n",
      "0s - loss:  0.0021\n",
      "Epoch 82/100\n",
      "0s - loss:  0.0020\n",
      "Epoch 83/100\n",
      "0s - loss:  0.0020\n",
      "Epoch 84/100\n",
      "0s - loss:  0.0019\n",
      "Epoch 85/100\n",
      "0s - loss:  0.0018\n",
      "Epoch 86/100\n",
      "0s - loss:  0.0018\n",
      "Epoch 87/100\n",
      "0s - loss:  0.0017\n",
      "Epoch 88/100\n",
      "0s - loss:  0.0017\n",
      "Epoch 89/100\n",
      "0s - loss:  0.0016\n",
      "Epoch 90/100\n",
      "0s - loss:  0.0016\n",
      "Epoch 91/100\n",
      "0s - loss:  0.0016\n",
      "Epoch 92/100\n",
      "0s - loss:  0.0015\n",
      "Epoch 93/100\n",
      "0s - loss:  0.0015\n",
      "Epoch 94/100\n",
      "0s - loss:  0.0014\n",
      "Epoch 95/100\n",
      "0s - loss:  0.0014\n",
      "Epoch 96/100\n",
      "0s - loss:  0.0014\n",
      "Epoch 97/100\n",
      "0s - loss:  0.0013\n",
      "Epoch 98/100\n",
      "0s - loss:  0.0013\n",
      "Epoch 99/100\n",
      "0s - loss:  0.0013\n",
      "Epoch 100/100\n",
      "0s - loss:  0.0012\n",
      "ğŸ‰ Steam æ¨¡å‹è®­ç»ƒå®Œæˆï¼\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from deepctr_torch.models import DeepFM\n",
    "from deepctr_torch.callbacks import EarlyStopping\n",
    "\n",
    "# 1. å‡†å¤‡æ•°æ®\n",
    "# ç¡®ä¿ä½ å·²ç»è¿è¡Œäº† Cell 2 å®šä¹‰äº† load_steam_data\n",
    "steam_csv_path = '../data/steam/train_data_Hardcore_Gamer.csv' # ä½ çš„æ–‡ä»¶å\n",
    "input_dict, linear_cols, dnn_cols, target = load_steam_data(steam_csv_path)\n",
    "\n",
    "# 2. æ£€æŸ¥è®¾å¤‡ (æœ‰æ˜¾å¡ç”¨æ˜¾å¡ï¼Œæ²¡æ˜¾å¡ç”¨ CPU)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"ğŸš€ ä½¿ç”¨è®¾å¤‡: {device}\")\n",
    "\n",
    "# 3. åˆå§‹åŒ– DeepFM æ¨¡å‹\n",
    "# å…³é”®ç‚¹ï¼šdnn_hidden_units å®šä¹‰äº†ç¥ç»ç½‘ç»œçš„å±‚æ•°å’Œå®½åº¦\n",
    "model_steam = DeepFM(linear_feature_columns=linear_cols, \n",
    "                     dnn_feature_columns=dnn_cols, \n",
    "                     task='binary', \n",
    "                     dnn_hidden_units=(128, 128), \n",
    "                     device=device)\n",
    "\n",
    "# 4. ç¼–è¯‘æ¨¡å‹\n",
    "# ä¼˜åŒ–å™¨ç”¨ Adamï¼ŒæŸå¤±å‡½æ•°ç”¨ äºŒå…ƒäº¤å‰ç†µ (binary_crossentropy) åªç›‘æ§ Lossï¼Œä¸è®¡ç®— Batch çº§ AUC\n",
    "model_steam.compile(\"adam\", \"binary_crossentropy\")\n",
    "\n",
    "# 5. å¼€å§‹è®­ç»ƒ (Fit)\n",
    "history_steam = model_steam.fit(input_dict, target, \n",
    "                                batch_size=64,\n",
    "                                epochs=100, \n",
    "                                verbose=2, \n",
    "                                validation_split=0.2) # åˆ’ 20% åšéªŒè¯é›†\n",
    "\n",
    "print(\"ğŸ‰ Steam æ¨¡å‹è®­ç»ƒå®Œæˆï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e185572d",
   "metadata": {},
   "source": [
    "## æ¨¡å‹ä¿å­˜ (Model Saving)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1166ab0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T13:56:51.057617Z",
     "iopub.status.busy": "2025-12-15T13:56:51.057385Z",
     "iopub.status.idle": "2025-12-15T13:56:51.105477Z",
     "shell.execute_reply": "2025-12-15T13:56:51.104548Z",
     "shell.execute_reply.started": "2025-12-15T13:56:51.057600Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Steam æ¨¡å‹æƒé‡å·²ä¿å­˜è‡³: deepfm_steam_weights.pth\n",
      "\n",
      "æç¤º: åœ¨ ModelScope å·¦ä¾§æ–‡ä»¶åˆ—è¡¨ä¸­åº”è¯¥èƒ½çœ‹åˆ°è¿™ä¸¤ä¸ª .pth æ–‡ä»¶äº†ã€‚\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# ğŸ’¾ æ¨¡å‹æƒé‡ä¿å­˜\n",
    "# ==========================================\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# 1. å®šä¹‰ä¿å­˜è·¯å¾„ (å»ºè®®æ”¾åœ¨å½“å‰å·¥ä½œç›®å½•)\n",
    "steam_model_path = 'deepfm_steam_weights.pth'\n",
    "\n",
    "# 2. ä¿å­˜ Steam æ¨¡å‹\n",
    "# åªæœ‰å½“æ¨¡å‹å·²ç»è®­ç»ƒè¿‡ (model_steam å­˜åœ¨) æ‰ä¿å­˜\n",
    "if 'model_steam' in locals():\n",
    "    torch.save(model_steam.state_dict(), steam_model_path)\n",
    "    print(f\"âœ… Steam æ¨¡å‹æƒé‡å·²ä¿å­˜è‡³: {steam_model_path}\")\n",
    "else:\n",
    "    print(\"âš ï¸ æœªæ£€æµ‹åˆ° model_steamï¼Œè·³è¿‡ä¿å­˜ã€‚\")\n",
    "\n",
    "print(\"\\næç¤º: åœ¨ ModelScope å·¦ä¾§æ–‡ä»¶åˆ—è¡¨ä¸­åº”è¯¥èƒ½çœ‹åˆ°è¿™ä¸¤ä¸ª .pth æ–‡ä»¶äº†ã€‚\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f53504",
   "metadata": {},
   "source": [
    "## åŠ è½½æƒé‡å¹¶å¯åŠ¨ API æœåŠ¡ (Loading & Serving)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64213e47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T13:56:56.166452Z",
     "iopub.status.busy": "2025-12-15T13:56:56.166235Z",
     "iopub.status.idle": "2025-12-15T13:56:56.317924Z",
     "shell.execute_reply": "2025-12-15T13:56:56.316960Z",
     "shell.execute_reply.started": "2025-12-15T13:56:56.166435Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ æ­£åœ¨åˆå§‹åŒ–æœåŠ¡ï¼Œé‡æ–°æ„å»ºæ¨¡å‹ç»“æ„...\n",
      "Loading Steam data from: ../data/steam/train_data_Hardcore_Gamer.csv ...\n",
      "Compressed Max Tag ID (Vocabulary Size): 296\n",
      "Detected Max Tag ID: 296\n",
      "âœ… Steam æ¨¡å‹åŠ è½½æˆåŠŸï¼\n",
      "ğŸš€ æœåŠ¡å·²å¯åŠ¨ï¼ç›‘å¬ç«¯å£ 5000...\n",
      "ä½ å¯ä»¥è¿è¡Œä¸‹ä¸€ä¸ª Cell æ¥æµ‹è¯•æ¥å£ã€‚\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://10.250.145.130:5000\n",
      "Press CTRL+C to quit\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# ğŸš€ æ¨¡å‹åŠ è½½ä¸ API æœåŠ¡å¯åŠ¨\n",
    "# ==========================================\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from deepctr_torch.models import DeepFM\n",
    "from flask import Flask, request, jsonify\n",
    "import threading\n",
    "\n",
    "# 1. é‡æ–°å®šä¹‰ä¸€äº›åŸºç¡€é…ç½® (é˜²æ­¢é‡å¯å†…æ ¸åå˜é‡ä¸¢å¤±)\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "STEAM_CSV = '../data/steam/train_data_Hardcore_Gamer.csv'   # ç¡®ä¿æ–‡ä»¶åå¯¹\n",
    "\n",
    "# 2. å®šä¹‰åŠ è½½å‡½æ•° (å¤ç”¨ä¹‹å‰çš„é€»è¾‘ï¼Œåªä¸ºäº†è·å–ç‰¹å¾åˆ—é…ç½®æ¥åˆå§‹åŒ–æ¨¡å‹)\n",
    "#    æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬éœ€è¦ import ä¹‹å‰å®šä¹‰çš„ load_steam_data\n",
    "#    å¦‚æœä½ é‡å¯äº†å†…æ ¸ï¼Œè¯·ç¡®ä¿æŠŠ\"æ•°æ®é¢„å¤„ç†\"é‚£ä¸ª Cell å…ˆè¿è¡Œä¸€éï¼Œè®©å‡½æ•°ç”Ÿæ•ˆã€‚\n",
    "\n",
    "print(\"ğŸ”„ æ­£åœ¨åˆå§‹åŒ–æœåŠ¡ï¼Œé‡æ–°æ„å»ºæ¨¡å‹ç»“æ„...\")\n",
    "\n",
    "# --- A. åŠ è½½ Steam æ¨¡å‹ ---\n",
    "# 1. è·å–ç‰¹å¾ç»“æ„ (ä¸éœ€è¦çœŸå® Input æ•°æ®ï¼Œåªéœ€è¦ Feature Columns)\n",
    "steam_input, steam_linear, steam_dnn, _ = load_steam_data(STEAM_CSV)\n",
    "# 2. åˆå§‹åŒ–ç©ºæ¨¡å‹\n",
    "service_model_steam = DeepFM(steam_linear, steam_dnn, task='binary', dnn_hidden_units=(128, 128), device=DEVICE)\n",
    "# 3. åŠ è½½æƒé‡\n",
    "try:\n",
    "    service_model_steam.load_state_dict(torch.load('deepfm_steam_weights.pth', map_location=DEVICE))\n",
    "    service_model_steam.eval() # åˆ‡æ¢åˆ°è¯„ä¼°æ¨¡å¼\n",
    "    print(\"âœ… Steam æ¨¡å‹åŠ è½½æˆåŠŸï¼\")\n",
    "except FileNotFoundError:\n",
    "    print(\"âŒ æœªæ‰¾åˆ° Steam æƒé‡æ–‡ä»¶ï¼ŒæœåŠ¡å°†æ— æ³•å¤„ç† Steam è¯·æ±‚ã€‚\")\n",
    "\n",
    "# ==========================================\n",
    "# 3. æ­å»º Flask API\n",
    "# ==========================================\n",
    "app = Flask(__name__)\n",
    "\n",
    "# å®šä¹‰æ¨èé€»è¾‘ (å°è£…å¥½çš„å·¥å…·å‡½æ•°)\n",
    "def get_recommendation(model, input_data, csv_path, top_k=3):\n",
    "    # 1. é¢„æµ‹\n",
    "    pred_ans = model.predict(input_data, batch_size=256)\n",
    "    # 2. è¯»åŸå§‹æ–‡ä»¶ç”¨äºå±•ç¤º\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df['score'] = pred_ans\n",
    "    # 3. æ’åº\n",
    "    top_items = df.sort_values(by='score', ascending=False).head(top_k)\n",
    "    # 4. æ ¼å¼åŒ–è¾“å‡º\n",
    "    results = []\n",
    "    for _, row in top_items.iterrows():\n",
    "        results.append({\n",
    "            \"id\": str(row['item_id']),\n",
    "            \"title\": row['title'],\n",
    "            \"score\": float(row['score']),\n",
    "            \"cover\": row.get('cover_url', row.get('pdf_url', '')),\n",
    "            \"tags\": row.get('tag_names', row.get('category', ''))\n",
    "        })\n",
    "    return results\n",
    "\n",
    "@app.route('/health', methods=['GET'])\n",
    "def health():\n",
    "    return jsonify({\"status\": \"ok\", \"device\": DEVICE})\n",
    "\n",
    "@app.route('/recommend', methods=['POST'])\n",
    "def recommend():\n",
    "    \"\"\"\n",
    "    API æ¥å£\n",
    "    Input JSON: { \"type\": \"steam\", \"top_k\": 3 }\n",
    "    \"\"\"\n",
    "    data = request.json\n",
    "    rec_type = data.get('type', 'steam')\n",
    "    top_k = data.get('top_k', 3)\n",
    "    \n",
    "    try:\n",
    "        if rec_type == 'steam':\n",
    "            # æ³¨æ„ï¼šå®é™…ç”Ÿäº§ä¸­ï¼Œinput_data åº”è¯¥æ ¹æ® user_id åŠ¨æ€ç”Ÿæˆ\n",
    "            # è¿™é‡Œæ¼”ç¤ºç”¨ï¼Œç›´æ¥ä½¿ç”¨å…¨é‡ input_data è¿›è¡Œé‡æ’\n",
    "            res = get_recommendation(service_model_steam, steam_input, STEAM_CSV, top_k)\n",
    "        else:\n",
    "            return jsonify({\"error\": \"Unknown type\"}), 400\n",
    "            \n",
    "        return jsonify({\n",
    "            \"code\": 200,\n",
    "            \"type\": rec_type,\n",
    "            \"data\": res\n",
    "        })\n",
    "    except Exception as e:\n",
    "        return jsonify({\"code\": 500, \"error\": str(e)})\n",
    "\n",
    "# ==========================================\n",
    "# 4. å¯åŠ¨æœåŠ¡ (åœ¨ Notebook ä¸­åå°è¿è¡Œ)\n",
    "# ==========================================\n",
    "def run_app():\n",
    "    # ç«¯å£è®¾ç½®ä¸º 6006 æˆ– 5000\n",
    "    app.run(host='0.0.0.0', port=5000, debug=False, use_reloader=False)\n",
    "\n",
    "# ä½¿ç”¨çº¿ç¨‹å¯åŠ¨ï¼Œé¿å…é˜»å¡ Notebook çš„ä¸»è¿›ç¨‹ï¼Œè¿™æ ·ä½ è¿˜èƒ½ç»§ç»­è·‘ä¸‹é¢çš„æµ‹è¯•ä»£ç \n",
    "t = threading.Thread(target=run_app)\n",
    "t.daemon = True\n",
    "t.start()\n",
    "\n",
    "print(\"ğŸš€ æœåŠ¡å·²å¯åŠ¨ï¼ç›‘å¬ç«¯å£ 5000...\")\n",
    "print(\"ä½ å¯ä»¥è¿è¡Œä¸‹ä¸€ä¸ª Cell æ¥æµ‹è¯•æ¥å£ã€‚\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f8e077",
   "metadata": {},
   "source": [
    "## æµ‹è¯•æœåŠ¡ (Client Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0dcfde8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T13:57:03.258057Z",
     "iopub.status.busy": "2025-12-15T13:57:03.257835Z",
     "iopub.status.idle": "2025-12-15T13:57:05.277965Z",
     "shell.execute_reply": "2025-12-15T13:57:05.277252Z",
     "shell.execute_reply.started": "2025-12-15T13:57:03.258042Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [15/Dec/2025 21:57:05] \"POST /recommend HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¡ è¯·æ±‚ Steam æ¨è...\n",
      "Steam Response: {'code': 200, 'data': [{'cover': 'https://shared.fastly.steamstatic.com/store_item_assets/steam/apps/3606480/bbdbbfce8a336864a974ee49419dabb6ccce5793/capsule_231x87_schinese.jpg?t=1765589367', 'id': '3606480', 'score': 0.9585115313529968, 'tags': 'åŠ¨ä½œ,å°„å‡»,è‚‰é¸½', 'title': 'Call of DutyÂ®: Black Ops 7'}, {'cover': 'https://shared.fastly.steamstatic.com/store_item_assets/steam/apps/1466860/capsule_231x87.jpg?t=1762295217', 'id': '1466860', 'score': 0.9539361000061035, 'tags': 'å¤šäºº', 'title': 'Age of Empires IV: Anniversary Edition'}], 'type': 'steam'}\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# ğŸ§ª æ¥å£æµ‹è¯• (æ¨¡æ‹Ÿ Dify è°ƒç”¨)\n",
    "# ==========================================\n",
    "import requests\n",
    "import time\n",
    "\n",
    "# ç­‰å¾…ä¸€ç§’è®©æœåŠ¡å®Œå…¨å¯åŠ¨\n",
    "time.sleep(2)\n",
    "\n",
    "url = \"http://127.0.0.1:5000/recommend\"\n",
    "\n",
    "# 1. æµ‹è¯• Steam æ¨è\n",
    "print(\"ğŸ“¡ è¯·æ±‚ Steam æ¨è...\")\n",
    "payload_steam = {\"type\": \"steam\", \"top_k\": 2}\n",
    "try:\n",
    "    resp = requests.post(url, json=payload_steam)\n",
    "    print(\"Steam Response:\", resp.json())\n",
    "except Exception as e:\n",
    "    print(\"Steam Request Failed:\", e)\n",
    "\n",
    "print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be84de28",
   "metadata": {},
   "source": [
    "## æœ€ç»ˆæœåŠ¡ä»£ç  Cell (ç›´æ¥è¿è¡Œ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e730234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# ğŸ® Steam DeepFM Server (Port 5000)\n",
    "# ==========================================\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from deepctr_torch.models import DeepFM\n",
    "from flask import Flask, request, jsonify\n",
    "from pyngrok import ngrok\n",
    "import threading\n",
    "\n",
    "# âš ï¸âš ï¸âš ï¸ å¡«å…¥ä½ çš„ Ngrok Token âš ï¸âš ï¸âš ï¸\n",
    "NGROK_TOKEN = \"è¿™é‡Œç²˜è´´ä½ çš„_Ngrok_Token\" \n",
    "PORT = 5000 # Steam æœåŠ¡è¿è¡Œåœ¨ 5000 ç«¯å£\n",
    "\n",
    "# ================= 1. åŠ è½½ Steam æ¨¡å‹ =================\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "STEAM_CSV = '../data/steam/train_data_Hardcore_Gamer.csv'\n",
    "\n",
    "print(\"ğŸ”„ æ­£åœ¨åˆå§‹åŒ– Steam æ¨¡å‹...\")\n",
    "\n",
    "# å‡è®¾ load_steam_data å·²ç»åœ¨å‰é¢çš„ Cell å®šä¹‰å¥½äº†\n",
    "try:\n",
    "    steam_input, steam_linear, steam_dnn, _ = load_steam_data(STEAM_CSV)\n",
    "    \n",
    "    # åˆå§‹åŒ–æ¨¡å‹ç»“æ„\n",
    "    model_steam = DeepFM(steam_linear, steam_dnn, task='binary', dnn_hidden_units=(128, 128), device=DEVICE)\n",
    "    \n",
    "    # åŠ è½½æƒé‡\n",
    "    model_steam.load_state_dict(torch.load('deepfm_steam_weights.pth', map_location=DEVICE))\n",
    "    model_steam.eval()\n",
    "    print(\"âœ… Steam æ¨¡å‹åŠ è½½æˆåŠŸï¼Ready to serve.\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Steam æ¨¡å‹åŠ è½½å¤±è´¥: {e}\")\n",
    "    # è¿™é‡Œä¸ºäº†ä¸æŠ¥é”™é€€å‡ºï¼Œä½ å¯ä»¥é€‰æ‹©æŠ›å‡ºå¼‚å¸¸æˆ–ç»§ç»­\n",
    "\n",
    "# ================= 2. å®šä¹‰ Flask åº”ç”¨ =================\n",
    "app_steam = Flask(__name__)\n",
    "\n",
    "def get_steam_recs(top_k=3):\n",
    "    # 1. é¢„æµ‹\n",
    "    pred_scores = model_steam.predict(steam_input, batch_size=256)\n",
    "    \n",
    "    # 2. è¯»å–å…ƒæ•°æ®\n",
    "    df = pd.read_csv(STEAM_CSV)\n",
    "    df['score'] = pred_scores\n",
    "    \n",
    "    # 3. æ’åº\n",
    "    top_items = df.sort_values(by='score', ascending=False).head(top_k)\n",
    "    \n",
    "    # 4. æ ¼å¼åŒ–\n",
    "    results = []\n",
    "    for _, row in top_items.iterrows():\n",
    "        results.append({\n",
    "            \"title\": row['title'],\n",
    "            \"score\": float(row['score']),\n",
    "            \"type\": str(row.get('tag_names', 'Unknown')),\n",
    "            \"cover\": str(row.get('cover_url', ''))\n",
    "        })\n",
    "    return results\n",
    "\n",
    "@app_steam.route('/recommend', methods=['POST'])\n",
    "def recommend_steam():\n",
    "    try:\n",
    "        req = request.json\n",
    "        top_k = req.get('top_k', 3)\n",
    "        print(f\"ğŸ® [Steam] æ”¶åˆ°è¯·æ±‚, Top {top_k}\")\n",
    "        \n",
    "        data = get_steam_recs(top_k)\n",
    "        return jsonify({\"status\": \"success\", \"service\": \"steam\", \"recommendations\": data})\n",
    "    except Exception as e:\n",
    "        return jsonify({\"status\": \"error\", \"message\": str(e)}), 500\n",
    "\n",
    "# ================= 3. å¯åŠ¨æœåŠ¡ =================\n",
    "def start_steam_server():\n",
    "    ngrok.set_auth_token(NGROK_TOKEN)\n",
    "    # æ€æ‰æ—§è¿›ç¨‹é˜²æ­¢å†²çª\n",
    "    ngrok.kill()\n",
    "    \n",
    "    public_url = ngrok.connect(PORT, bind_tls=True).public_url\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"ğŸ® Steam æœåŠ¡å·²å¯åŠ¨ï¼API åœ°å€: {public_url}/recommend\")\n",
    "    print(\"=\"*50 + \"\\n\")\n",
    "    \n",
    "    app_steam.run(port=PORT, use_reloader=False)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    t = threading.Thread(target=start_steam_server)\n",
    "    t.daemon = True\n",
    "    t.start()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
